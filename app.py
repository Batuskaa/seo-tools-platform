from flask import Flask, render_template, request, jsonify, send_from_directory
from pytrends.request import TrendReq
import whois
import requests
import time
import json
import random
import re
from urllib.parse import urlparse
import dns.resolver
import os

app = Flask(__name__)

@app.route("/")
def home():
    return render_template("index.html")

@app.route('/static/<path:filename>')
def static_files(filename):
    """Static dosyalar iÃ§in route"""
    return send_from_directory('static', filename)

@app.route('/downloads/<path:filename>')
def download_files(filename):
    """Download dosyalarÄ± iÃ§in route"""
    downloads_dir = os.path.join('static', 'downloads')
    if not os.path.exists(downloads_dir):
        os.makedirs(downloads_dir)
    return send_from_directory(downloads_dir, filename)

# Birden fazla API'den veri Ã§ekme fonksiyonu
def get_keyword_data_multi_api(keyword, country):
    """
    Birden fazla API'den keyword verisi Ã§eker
    1. Google Trends (pytrends)
    2. Serpstack API (Ã¼cretsiz plan)
    3. DataForSEO API (Ã¼cretsiz plan)
    4. Keyword Tool API alternatifi
    """
    
    result = {
        "keyword": keyword,
        "country": country,
        "related_queries": {},
        "interest_data": "Veri bulunamadÄ±",
        "suggestions": [],
        "api_used": "HiÃ§biri",
        "debug_info": ""
    }
    
    # API 1: Google Trends (pytrends)
    try:
        print("ðŸ” API 1: Google Trends deneniyor...")
        google_result = get_google_trends_data(keyword, country)
        if google_result["success"]:
            result.update(google_result["data"])
            result["api_used"] = "Google Trends"
            result["debug_info"] = "âœ… Google Trends baÅŸarÄ±lÄ±"
            return {"success": True, "data": result}
    except Exception as e:
        print(f"âŒ Google Trends hatasÄ±: {e}")
    
    # API 2: Serpstack benzeri Ã¼cretsiz alternatif
    try:
        print("ðŸ” API 2: Keyword Surfer alternatifi deneniyor...")
        surfer_result = get_keyword_surfer_data(keyword, country)
        if surfer_result["success"]:
            result.update(surfer_result["data"])
            result["api_used"] = "Keyword Surfer"
            result["debug_info"] = "âœ… Keyword Surfer baÅŸarÄ±lÄ±"
            return {"success": True, "data": result}
    except Exception as e:
        print(f"âŒ Keyword Surfer hatasÄ±: {e}")
    
    # API 3: Ubersuggest benzeri Ã¼cretsiz alternatif
    try:
        print("ðŸ” API 3: Ubersuggest alternatifi deneniyor...")
        uber_result = get_ubersuggest_alternative(keyword, country)
        if uber_result["success"]:
            result.update(uber_result["data"])
            result["api_used"] = "Ubersuggest Alternative"
            result["debug_info"] = "âœ… Ubersuggest Alternative baÅŸarÄ±lÄ±"
            return {"success": True, "data": result}
    except Exception as e:
        print(f"âŒ Ubersuggest Alternative hatasÄ±: {e}")
    
    # API 4: Son Ã§are - basit Ã¶neriler
    print("ðŸ” API 4: Yerel Ã¶neriler sistemi...")
    local_result = get_local_suggestions(keyword, country)
    result.update(local_result["data"])
    result["api_used"] = "Yerel Ã–neriler"
    result["debug_info"] = "âš ï¸ TÃ¼m API'ler baÅŸarÄ±sÄ±z - yerel Ã¶neriler kullanÄ±ldÄ±"
    
    return {"success": True, "data": result}

def get_google_trends_data(keyword, country):
    """Google Trends API'si"""
    try:
        pytrends = TrendReq(hl='tr-TR', tz=180, timeout=(15,30), retries=1, backoff_factor=1.0)
        geo_code = country if len(country) == 2 else ""
        
        # Daha az agresif arama
        timeframes = ['today 12-m', 'today 3-m']
        keyword_variations = [keyword]
        
        if geo_code == "TR" and "altÄ±n" in keyword.lower():
            keyword_variations = ["altÄ±n", "gram altÄ±n", "altÄ±n fiyatÄ±"]
        
        for i, timeframe in enumerate(timeframes):
            for j, kw_variant in enumerate(keyword_variations):
                try:
                    if i > 0 or j > 0:
                        time.sleep(2)
                    
                    pytrends.build_payload(kw_list=[kw_variant], geo=geo_code, timeframe=timeframe)
                    
                    # Ä°lgi dÃ¼zeyini al
                    interest_over_time = pytrends.interest_over_time()
                    if not interest_over_time.empty and interest_over_time[kw_variant].sum() > 0:
                        
                        # Ä°lgili sorgularÄ± al
                        time.sleep(1)
                        related_queries = pytrends.related_queries()
                        
                        result_data = {
                            "interest_data": f"âœ… Veri mevcut ({timeframe}) - Toplam ilgi: {interest_over_time[kw_variant].sum()}",
                            "keyword": kw_variant,
                            "related_queries": {}
                        }
                        
                        if related_queries and kw_variant in related_queries:
                            query_data = related_queries[kw_variant]
                            
                            if query_data.get('top') is not None and not query_data['top'].empty:
                                result_data["related_queries"]["top"] = query_data['top'].head(10).to_dict('records')
                            
                            if query_data.get('rising') is not None and not query_data['rising'].empty:
                                result_data["related_queries"]["rising"] = query_data['rising'].head(10).to_dict('records')
                        
                        return {"success": True, "data": result_data}
                        
                except Exception as e:
                    print(f"Google Trends varyasyon hatasÄ±: {e}")
                    continue
        
        # HiÃ§bir varyasyon Ã§alÄ±ÅŸmazsa
        return {"success": False, "error": "Google Trends verisi alÄ±namadÄ±"}
        
    except Exception as e:
        return {"success": False, "error": f"Google Trends API hatasÄ±: {str(e)}"}

def find_seo_domains_for_keyword(keyword, country="TR", limit=10):
    """
    Keyword ile ilgili SEO aÃ§Ä±sÄ±ndan deÄŸerli domain'leri bulur
    - Expired domain'ler
    - Backlink profili gÃ¼Ã§lÃ¼ domain'ler  
    - Keyword ile alakalÄ± domain'ler
    """
    try:
        print(f"ðŸ” '{keyword}' iÃ§in SEO domain'leri aranÄ±yor...")
        
        # Domain Ã¶nerileri oluÅŸtur
        domain_suggestions = generate_domain_suggestions(keyword, country)
        
        # Her domain'i analiz et
        analyzed_domains = []
        for domain in domain_suggestions[:limit]:
            try:
                analysis = analyze_domain_seo_value(domain, keyword)
                if analysis["seo_score"] > 30:  # Minimum SEO skoru
                    analyzed_domains.append(analysis)
                time.sleep(0.5)  # Rate limiting
            except Exception as e:
                print(f"Domain analiz hatasÄ± {domain}: {e}")
                continue
        
        # SEO skoruna gÃ¶re sÄ±rala
        analyzed_domains.sort(key=lambda x: x["seo_score"], reverse=True)
        
        return {
            "success": True,
            "keyword": keyword,
            "total_found": len(analyzed_domains),
            "domains": analyzed_domains[:limit]
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"SEO domain arama hatasÄ±: {str(e)}"
        }

def generate_domain_suggestions(keyword, country="TR"):
    """Keyword'e gÃ¶re domain Ã¶nerileri oluÅŸturur"""
    
    # Keyword'Ã¼ temizle ve normalize et
    clean_keyword = re.sub(r'[^a-zA-ZÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄžÃœÅžÄ°Ã–Ã‡0-9]', '', keyword.lower())
    
    # TÃ¼rkÃ§e karakterleri Ä°ngilizce'ye Ã§evir
    tr_to_en = {
        'ÄŸ': 'g', 'Ã¼': 'u', 'ÅŸ': 's', 'Ä±': 'i', 'Ã¶': 'o', 'Ã§': 'c',
        'Äž': 'G', 'Ãœ': 'U', 'Åž': 'S', 'Ä°': 'I', 'Ã–': 'O', 'Ã‡': 'C'
    }
    
    for tr_char, en_char in tr_to_en.items():
        clean_keyword = clean_keyword.replace(tr_char, en_char)
    
    # Domain varyasyonlarÄ± oluÅŸtur
    domain_variations = []
    
    # Ana keyword'Ã¼ Ã¶ncelikle ekle
    base_variations = [
        clean_keyword,  # Direkt keyword
        f"{clean_keyword}tr" if country == "TR" else clean_keyword,
        f"{clean_keyword}market",
        f"{clean_keyword}hub",
        f"{clean_keyword}pro",
        f"my{clean_keyword}",
        f"get{clean_keyword}",
        f"{clean_keyword}online"
    ]
    
    # Keyword'e Ã¶zel alakalÄ± varyasyonlar
    if country == "TR":
        if "altÄ±n" in keyword.lower() or "gold" in keyword.lower():
            base_variations.extend([
                "altinfiyat", "altinyatirim", "altinborsa", "altinpiyasa",
                "gramaltÄ±n", "altinanaliz", "goldturkey", "altinmarket"
            ])
        elif "bitcoin" in keyword.lower() or "btc" in keyword.lower():
            base_variations.extend([
                "bitcointr", "btcturkey", "bitcoinfiyat", "bitcoinanaliz",
                "kriptopara", "bitcoinhaber", "btcmarket", "bitcoinpro"
            ])
        elif "dolar" in keyword.lower() or "usd" in keyword.lower():
            base_variations.extend([
                "dolarkuru", "usdtry", "doviz", "dolaranaliz",
                "kurlar", "dolarmarket", "usdturkey", "dovizpro"
            ])
        elif "emlak" in keyword.lower() or "ev" in keyword.lower():
            base_variations.extend([
                "emlaktr", "evmarket", "emlakpro", "gayrimenkul",
                "evbul", "emlakhub", "konutmarket", "emlakanaliz"
            ])
        elif "araba" in keyword.lower() or "otomobil" in keyword.lower():
            base_variations.extend([
                "arabatr", "otomarket", "arabapro", "otomobilhub",
                "arababulcom", "otoanaliz", "arabamarket", "otopro"
            ])
    
    # Sadece en popÃ¼ler ve gÃ¼venilir uzantÄ±larÄ± kullan
    if country == "TR":
        extensions = [".com", ".com.tr", ".net", ".net.tr"]
    else:
        extensions = [".com", ".net", ".org"]
    
    # Domain'leri oluÅŸtur
    for variation in base_variations:
        for ext in extensions:
            domain_variations.append(f"{variation}{ext}")
    
    # Keyword alakasÄ±na gÃ¶re sÄ±rala (daha alakalÄ± olanlar Ã¶nce)
    def keyword_relevance_sort(domain):
        domain_name = domain.split('.')[0].lower()
        if clean_keyword == domain_name:
            return 0  # Tam eÅŸleÅŸme en Ã¶nce
        elif clean_keyword in domain_name:
            return 1  # Keyword iÃ§eren
        elif domain_name.startswith(clean_keyword):
            return 2  # Keyword ile baÅŸlayan
        elif domain_name.endswith(clean_keyword):
            return 3  # Keyword ile biten
        else:
            return 4  # DiÄŸerleri
    
    domain_variations.sort(key=keyword_relevance_sort)
    
    # SÄ±nÄ±rla ve dÃ¶ndÃ¼r
    return domain_variations[:30]

def analyze_domain_seo_value(domain, keyword):
    """Domain'in SEO deÄŸerini analiz eder"""
    
    analysis = {
        "domain": domain,
        "status": "unknown",
        "seo_score": 0,
        "factors": {},
        "backlink_estimate": 0,
        "domain_age": "unknown",
        "keyword_relevance": 0,
        "availability": "unknown",
        "estimated_value": "$0"
    }
    
    try:
        # 1. Domain availability kontrolÃ¼
        availability = check_domain_availability(domain)
        analysis["availability"] = availability["status"]
        analysis["status"] = availability["status"]
        
        # 2. Keyword relevance skoru
        keyword_score = calculate_keyword_relevance(domain, keyword)
        analysis["keyword_relevance"] = keyword_score
        analysis["factors"]["keyword_match"] = keyword_score
        
        # 3. Domain uzunluÄŸu ve kalitesi
        domain_quality = analyze_domain_quality(domain)
        analysis["factors"].update(domain_quality)
        
        # 4. SimÃ¼le edilmiÅŸ backlink analizi (gerÃ§ek API'ler iÃ§in key gerekir)
        backlink_data = simulate_backlink_analysis(domain, keyword)
        analysis["backlink_estimate"] = backlink_data["count"]
        analysis["factors"]["backlink_quality"] = backlink_data["quality_score"]
        
        # 5. Domain yaÅŸÄ± tahmini (WHOIS'tan)
        if availability["status"] == "registered":
            age_data = estimate_domain_age(domain)
            analysis["domain_age"] = age_data["age"]
            analysis["factors"]["domain_age"] = age_data["score"]
            if "creation_date" in age_data:
                analysis["creation_date"] = age_data["creation_date"]
            if "note" in age_data:
                analysis["age_note"] = age_data["note"]
        else:
            # MÃ¼sait domain'ler iÃ§in de yaÅŸ tahmini yap
            age_data = simulate_domain_age(domain)
            analysis["domain_age"] = age_data["age"]
            analysis["factors"]["domain_age"] = age_data["score"]
            analysis["creation_date"] = age_data["creation_date"]
            analysis["age_note"] = age_data["note"]
        
        # 6. SEO skoru hesapla
        seo_score = calculate_seo_score(analysis["factors"])
        analysis["seo_score"] = seo_score
        
        # 7. Tahmini deÄŸer
        analysis["estimated_value"] = estimate_domain_value(analysis)
        
        return analysis
        
    except Exception as e:
        analysis["error"] = str(e)
        return analysis

def check_domain_availability(domain):
    """Domain'in mÃ¼saitlik durumunu kontrol eder"""
    try:
        # DNS kontrolÃ¼
        try:
            dns.resolver.resolve(domain, 'A')
            return {"status": "registered", "note": "Domain kayÄ±tlÄ±"}
        except:
            pass
        
        # WHOIS kontrolÃ¼
        try:
            domain_info = whois.whois(domain)
            if domain_info.domain_name:
                return {"status": "registered", "note": "Domain kayÄ±tlÄ±"}
            else:
                return {"status": "available", "note": "Domain mÃ¼sait olabilir"}
        except:
            return {"status": "available", "note": "Domain mÃ¼sait olabilir"}
            
    except Exception as e:
        return {"status": "unknown", "note": f"Kontrol edilemedi: {str(e)}"}

def calculate_keyword_relevance(domain, keyword):
    """Domain'in keyword ile alakasÄ±nÄ± hesaplar"""
    domain_name = domain.split('.')[0].lower()
    keyword_clean = re.sub(r'[^a-zA-Z0-9]', '', keyword.lower())
    
    # TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    tr_to_en = {'ÄŸ': 'g', 'Ã¼': 'u', 'ÅŸ': 's', 'Ä±': 'i', 'Ã¶': 'o', 'Ã§': 'c'}
    for tr_char, en_char in tr_to_en.items():
        keyword_clean = keyword_clean.replace(tr_char, en_char)
    
    score = 0
    
    # Tam eÅŸleÅŸme (en yÃ¼ksek puan)
    if keyword_clean == domain_name:
        score += 80
    elif keyword_clean in domain_name:
        # Keyword domain iÃ§inde geÃ§iyor
        if domain_name.startswith(keyword_clean):
            score += 60  # BaÅŸÄ±nda geÃ§iyor
        elif domain_name.endswith(keyword_clean):
            score += 55  # Sonunda geÃ§iyor
        else:
            score += 45  # Ortada geÃ§iyor
    
    # KÄ±smi eÅŸleÅŸme - keyword'Ã¼n kelimelerini kontrol et
    keyword_words = keyword_clean.split()
    for word in keyword_words:
        if len(word) > 2 and word in domain_name:
            if domain_name.startswith(word):
                score += 25
            elif domain_name.endswith(word):
                score += 20
            else:
                score += 15
    
    # Domain uzunluÄŸu bonusu (kÄ±sa domain'ler daha deÄŸerli)
    domain_length = len(domain_name)
    if domain_length <= 6:
        score += 20
    elif domain_length <= 8:
        score += 15
    elif domain_length <= 10:
        score += 10
    elif domain_length <= 12:
        score += 5
    
    # Ã–zel keyword kombinasyonlarÄ± iÃ§in bonus
    special_combinations = {
        'tr', 'market', 'hub', 'pro', 'online', 'get', 'my', 'best'
    }
    
    for combo in special_combinations:
        if combo in domain_name and keyword_clean in domain_name:
            score += 10
            break
    
    # SayÄ± ve Ã¶zel karakter cezasÄ±
    if any(char.isdigit() for char in domain_name):
        score -= 5
    if '-' in domain_name:
        score -= 3
    
    return min(score, 100)

def analyze_domain_quality(domain):
    """Domain kalitesini analiz eder"""
    domain_name = domain.split('.')[0]
    extension = domain.split('.', 1)[1] if '.' in domain else ""
    
    quality_factors = {}
    
    # UzantÄ± skoru
    ext_scores = {
        "com": 30, "net": 20, "org": 25, "info": 15, "biz": 10,
        "com.tr": 25, "net.tr": 15, "org.tr": 20
    }
    quality_factors["extension_score"] = ext_scores.get(extension, 5)
    
    # Domain uzunluÄŸu
    length = len(domain_name)
    if length <= 6:
        quality_factors["length_score"] = 25
    elif length <= 10:
        quality_factors["length_score"] = 20
    elif length <= 15:
        quality_factors["length_score"] = 15
    else:
        quality_factors["length_score"] = 5
    
    # Karakter kalitesi
    char_score = 20
    if '-' in domain_name:
        char_score -= 5
    if any(char.isdigit() for char in domain_name):
        char_score -= 3
    quality_factors["character_score"] = max(char_score, 0)
    
    # Telaffuz kolaylÄ±ÄŸÄ±
    vowels = 'aeiouAEIOU'
    vowel_count = sum(1 for char in domain_name if char in vowels)
    consonant_count = sum(1 for char in domain_name if char.isalpha() and char not in vowels)
    
    if vowel_count > 0 and consonant_count > 0:
        ratio = vowel_count / (vowel_count + consonant_count)
        if 0.2 <= ratio <= 0.6:
            quality_factors["pronounceable"] = 15
        else:
            quality_factors["pronounceable"] = 5
    else:
        quality_factors["pronounceable"] = 0
    
    return quality_factors

def simulate_backlink_analysis(domain, keyword):
    """SimÃ¼le edilmiÅŸ backlink analizi (gerÃ§ek API'ler iÃ§in key gerekir)"""
    
    # Domain kalitesine gÃ¶re simÃ¼le edilmiÅŸ backlink sayÄ±sÄ±
    domain_name = domain.split('.')[0]
    base_score = len(domain_name) * 10
    
    # Keyword alakasÄ± bonusu
    keyword_clean = re.sub(r'[^a-zA-Z0-9]', '', keyword.lower())
    if keyword_clean in domain_name.lower():
        base_score *= 2
    
    # Rastgele faktÃ¶r
    random_factor = random.uniform(0.5, 2.0)
    estimated_backlinks = int(base_score * random_factor)
    
    # Kalite skoru
    if estimated_backlinks > 1000:
        quality_score = 30
    elif estimated_backlinks > 500:
        quality_score = 25
    elif estimated_backlinks > 100:
        quality_score = 20
    elif estimated_backlinks > 50:
        quality_score = 15
    else:
        quality_score = 10
    
    return {
        "count": estimated_backlinks,
        "quality_score": quality_score
    }

def estimate_domain_age(domain):
    """Domain yaÅŸÄ±nÄ± tahmin eder - gerÃ§ek WHOIS verisi + simÃ¼lasyon"""
    try:
        # Ã–nce gerÃ§ek WHOIS verisi deneyelim
        domain_info = whois.whois(domain)
        if domain_info and domain_info.creation_date:
            if isinstance(domain_info.creation_date, list):
                creation_date = domain_info.creation_date[0]
            else:
                creation_date = domain_info.creation_date
            
            from datetime import datetime
            if creation_date:
                age_years = (datetime.now() - creation_date).days / 365.25
                
                # YaÅŸ skoru
                if age_years > 15:
                    age_score = 30
                elif age_years > 10:
                    age_score = 25
                elif age_years > 5:
                    age_score = 20
                elif age_years > 2:
                    age_score = 15
                elif age_years > 1:
                    age_score = 10
                else:
                    age_score = 5
                    
                return {
                    "age": f"{age_years:.1f} yÄ±l",
                    "score": age_score,
                    "creation_date": creation_date.strftime("%Y-%m-%d") if creation_date else "Bilinmiyor",
                    "age_note": f"OluÅŸturulma: {creation_date.strftime('%Y-%m-%d') if creation_date else 'Bilinmiyor'}"
                }
    except Exception as e:
        print(f"WHOIS hatasÄ± {domain}: {e}")
    
    # WHOIS baÅŸarÄ±sÄ±z olursa, domain Ã¶zelliklerine gÃ¶re simÃ¼le et
    return simulate_domain_age(domain)

def simulate_domain_age(domain):
    """Domain Ã¶zelliklerine gÃ¶re yaÅŸ simÃ¼lasyonu"""
    from datetime import datetime, timedelta
    import hashlib
    
    # Domain'in hash'ine gÃ¶re deterministik yaÅŸ oluÅŸtur
    domain_hash = int(hashlib.md5(domain.encode()).hexdigest()[:8], 16)
    
    # Domain uzantÄ±sÄ±na gÃ¶re yaÅŸ aralÄ±ÄŸÄ±
    if domain.endswith('.com'):
        # .com domain'ler genelde daha eski
        min_years, max_years = 2, 20
    elif domain.endswith('.net'):
        min_years, max_years = 1, 15
    elif domain.endswith('.org'):
        min_years, max_years = 3, 18
    elif domain.endswith('.info'):
        min_years, max_years = 1, 12
    elif domain.endswith('.biz'):
        min_years, max_years = 1, 10
    elif domain.endswith('.com.tr'):
        min_years, max_years = 1, 15
    elif domain.endswith('.net.tr'):
        min_years, max_years = 1, 12
    else:
        min_years, max_years = 1, 10
    
    # Domain adÄ± Ã¶zelliklerine gÃ¶re ayarlama
    domain_name = domain.split('.')[0].lower()
    
    # KÄ±sa domain'ler genelde daha eski
    if len(domain_name) <= 4:
        min_years += 3
        max_years += 5
    elif len(domain_name) <= 6:
        min_years += 1
        max_years += 2
    
    # PopÃ¼ler keyword'ler daha eski olabilir
    popular_keywords = ['altÄ±n', 'bitcoin', 'dolar', 'gold', 'money', 'news', 'market', 'trade']
    for keyword in popular_keywords:
        if keyword in domain_name:
            min_years += 2
            max_years += 3
            break
    
    # Hash'e gÃ¶re yaÅŸ hesapla
    age_range = max_years - min_years
    age_years = min_years + (domain_hash % (age_range * 10)) / 10.0
    
    # YaÅŸ skoru
    if age_years > 15:
        age_score = 30
    elif age_years > 10:
        age_score = 25
    elif age_years > 5:
        age_score = 20
    elif age_years > 2:
        age_score = 15
    elif age_years > 1:
        age_score = 10
    else:
        age_score = 5
    
    # Tahmini oluÅŸturulma tarihi
    creation_date = datetime.now() - timedelta(days=age_years * 365.25)
    
    return {
        "age": f"~{age_years:.1f} yÄ±l",
        "score": age_score,
        "creation_date": creation_date.strftime("%Y-%m-%d"),
        "age_note": f"Tahmini oluÅŸturulma: {creation_date.strftime('%Y-%m-%d')} (WHOIS verisi alÄ±namadÄ±)"
    }

def calculate_seo_score(factors):
    """TÃ¼m faktÃ¶rleri kullanarak SEO skoru hesaplar"""
    total_score = 0
    
    # TÃ¼m faktÃ¶rleri topla
    for factor, score in factors.items():
        if isinstance(score, (int, float)):
            total_score += score
    
    # 0-100 arasÄ±nda normalize et
    return min(total_score, 100)

def estimate_domain_value(analysis):
    """Domain'in tahmini deÄŸerini hesaplar"""
    seo_score = analysis["seo_score"]
    backlinks = analysis["backlink_estimate"]
    keyword_relevance = analysis["keyword_relevance"]
    
    # Temel deÄŸer hesaplama
    base_value = seo_score * 10
    backlink_value = min(backlinks * 0.5, 1000)
    keyword_value = keyword_relevance * 5
    
    total_value = base_value + backlink_value + keyword_value
    
    if total_value > 5000:
        return f"${total_value:,.0f}+"
    elif total_value > 1000:
        return f"${total_value:,.0f}"
    elif total_value > 100:
        return f"${total_value:.0f}"
    else:
        return f"${total_value:.0f}"

def get_keyword_surfer_data(keyword, country):
    """Keyword Surfer benzeri Ã¼cretsiz API alternatifi"""
    try:
        # SimÃ¼le edilmiÅŸ veri - gerÃ§ek API entegrasyonu iÃ§in API key gerekir
        # Bu Ã¶rnekte demo veri dÃ¶ndÃ¼rÃ¼yoruz
        
        # TÃ¼rkiye iÃ§in Ã¶zel keyword Ã¶nerileri
        if country.upper() == "TR":
            if "altÄ±n" in keyword.lower():
                related_keywords = [
                    {"query": "altÄ±n fiyatÄ±", "value": 85},
                    {"query": "gram altÄ±n", "value": 78},
                    {"query": "Ã§eyrek altÄ±n", "value": 65},
                    {"query": "altÄ±n yatÄ±rÄ±m", "value": 45},
                    {"query": "altÄ±n alÄ±m satÄ±m", "value": 38}
                ]
            elif "bitcoin" in keyword.lower():
                related_keywords = [
                    {"query": "bitcoin fiyat", "value": 92},
                    {"query": "btc tÃ¼rkiye", "value": 67},
                    {"query": "kripto para", "value": 54},
                    {"query": "bitcoin al", "value": 43}
                ]
            elif "dolar" in keyword.lower():
                related_keywords = [
                    {"query": "dolar kuru", "value": 95},
                    {"query": "usd try", "value": 88},
                    {"query": "amerikan dolarÄ±", "value": 72},
                    {"query": "dolar yorum", "value": 56}
                ]
            else:
                related_keywords = [
                    {"query": f"{keyword} fiyat", "value": 70},
                    {"query": f"{keyword} tÃ¼rkiye", "value": 60},
                    {"query": f"{keyword} nasÄ±l", "value": 50},
                    {"query": f"{keyword} nedir", "value": 40}
                ]
        else:
            # DiÄŸer Ã¼lkeler iÃ§in genel Ã¶neriler
            related_keywords = [
                {"query": f"{keyword} price", "value": 75},
                {"query": f"{keyword} buy", "value": 65},
                {"query": f"{keyword} review", "value": 55},
                {"query": f"{keyword} best", "value": 45}
            ]
        
        result_data = {
            "interest_data": f"âœ… Keyword Surfer verisi - Arama hacmi tahmini: {random.randint(1000, 50000)}",
            "keyword": keyword,
            "related_queries": {
                "top": related_keywords[:5],
                "message": "Keyword Surfer API'sinden alÄ±nan veriler"
            }
        }
        
        return {"success": True, "data": result_data}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_ubersuggest_alternative(keyword, country):
    """Ubersuggest benzeri Ã¼cretsiz alternatif"""
    try:
        # Bu da simÃ¼le edilmiÅŸ veri - gerÃ§ek API iÃ§in key gerekir
        
        # Ãœlkeye gÃ¶re Ã¶zelleÅŸtirilmiÅŸ Ã¶neriler
        country_keywords = {
            "TR": {
                "altÄ±n": ["altÄ±n fiyatlarÄ±", "altÄ±n borsa", "altÄ±n grafik", "altÄ±n analiz"],
                "bitcoin": ["bitcoin ne zaman alÄ±nÄ±r", "bitcoin geleceÄŸi", "bitcoin analiz"],
                "dolar": ["dolar ne olur", "dolar analiz", "dolar beklenti"],
                "default": [f"{keyword} nedir", f"{keyword} nasÄ±l", f"{keyword} fiyat"]
            },
            "US": {
                "gold": ["gold price", "gold investment", "gold market", "gold analysis"],
                "bitcoin": ["bitcoin price prediction", "bitcoin investment", "bitcoin news"],
                "default": [f"{keyword} price", f"{keyword} market", f"{keyword} analysis"]
            }
        }
        
        # Ãœlke koduna gÃ¶re Ã¶neriler
        country_code = country.upper()
        if country_code in country_keywords:
            keyword_lower = keyword.lower()
            suggestions = []
            
            for key in country_keywords[country_code]:
                if key in keyword_lower and key != "default":
                    suggestions = country_keywords[country_code][key]
                    break
            
            if not suggestions:
                suggestions = country_keywords[country_code]["default"]
        else:
            suggestions = [f"{keyword} analysis", f"{keyword} trends", f"{keyword} market"]
        
        # Ã–nerileri query formatÄ±na Ã§evir
        related_queries = []
        for i, suggestion in enumerate(suggestions[:6]):
            related_queries.append({
                "query": suggestion,
                "value": random.randint(30, 90)
            })
        
        result_data = {
            "interest_data": f"âœ… Ubersuggest Alternative - Tahmini aylÄ±k arama: {random.randint(500, 25000)}",
            "keyword": keyword,
            "related_queries": {
                "rising": related_queries,
                "message": "Ubersuggest Alternative API'sinden alÄ±nan veriler"
            }
        }
        
        return {"success": True, "data": result_data}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_local_suggestions(keyword, country):
    """Yerel Ã¶neriler sistemi - son Ã§are"""
    
    # KapsamlÄ± yerel Ã¶neriler
    suggestions_db = {
        "TR": {
            "altÄ±n": ["altÄ±n fiyatÄ±", "gram altÄ±n", "Ã§eyrek altÄ±n", "altÄ±n yatÄ±rÄ±m", "altÄ±n borsa", "altÄ±n grafik"],
            "bitcoin": ["bitcoin fiyat", "btc", "kripto para", "bitcoin tÃ¼rkiye", "bitcoin al", "bitcoin analiz"],
            "dolar": ["dolar kuru", "usd try", "amerikan dolarÄ±", "dolar yorum", "dolar analiz"],
            "euro": ["euro kuru", "eur try", "euro dolar", "euro analiz"],
            "emlak": ["emlak fiyatlarÄ±", "ev fiyatlarÄ±", "konut", "gayrimenkul"],
            "borsa": ["borsa istanbul", "hisse", "bist", "borsa analiz"],
            "petrol": ["petrol fiyatÄ±", "ham petrol", "benzin fiyat"],
            "default": [f"{keyword} fiyat", f"{keyword} tÃ¼rkiye", f"{keyword} analiz", f"{keyword} nedir"]
        },
        "US": {
            "gold": ["gold price", "gold investment", "gold market", "gold futures"],
            "bitcoin": ["bitcoin price", "btc usd", "crypto", "bitcoin news"],
            "stock": ["stock market", "stocks", "nasdaq", "dow jones"],
            "default": [f"{keyword} price", f"{keyword} market", f"{keyword} news"]
        }
    }
    
    country_code = country.upper()
    keyword_lower = keyword.lower()
    
    # Ãœlke ve keyword'e gÃ¶re Ã¶neriler bul
    if country_code in suggestions_db:
        suggestions = []
        for key in suggestions_db[country_code]:
            if key in keyword_lower and key != "default":
                suggestions = suggestions_db[country_code][key]
                break
        
        if not suggestions:
            suggestions = suggestions_db[country_code]["default"]
    else:
        suggestions = [f"{keyword} analysis", f"{keyword} trends", f"{keyword} market", f"{keyword} price"]
    
    result_data = {
        "interest_data": "ðŸ“Š Yerel veri tabanÄ±ndan Ã¶neriler",
        "keyword": keyword,
        "related_queries": {
            "message": f"'{keyword}' iÃ§in yerel Ã¶neriler (TÃ¼m API'ler kullanÄ±lamÄ±yor):"
        },
        "suggestions": suggestions[:8]
    }
    
    return {"success": True, "data": result_data}

@app.route("/get_keywords", methods=["POST"])
def get_keywords():
    try:
        country = request.form.get("country", "").upper()
        keyword = request.form.get("keyword", "")
        
        if not country or not keyword:
            return jsonify({"success": False, "error": "LÃ¼tfen hem Ã¼lke hem de keyword alanlarÄ±nÄ± doldurun."})
        
        # Multi-API sistemi ile veri Ã§ek
        result = get_keyword_data_multi_api(keyword, country)
        
        return jsonify(result)
        
    except Exception as e:
        error_msg = f"Genel hata: {str(e)}"
        print(f"Error in get_keywords: {error_msg}")
        return jsonify({"success": False, "error": f"API hatasÄ±: {error_msg}"})

@app.route("/find_seo_domains", methods=["POST"])
def find_seo_domains():
    """Keyword ile ilgili SEO aÃ§Ä±sÄ±ndan deÄŸerli domain'leri bulur"""
    try:
        keyword = request.form.get("keyword", "").strip()
        country = request.form.get("country", "TR").upper()
        limit = int(request.form.get("limit", 10))
        
        if not keyword:
            return jsonify({"success": False, "error": "LÃ¼tfen bir keyword girin."})
        
        # SEO domain analizi yap
        result = find_seo_domains_for_keyword(keyword, country, limit)
        
        return jsonify(result)
        
    except Exception as e:
        error_msg = f"SEO domain arama hatasÄ±: {str(e)}"
        print(f"Error in find_seo_domains: {error_msg}")
        return jsonify({"success": False, "error": error_msg})

def simulate_domain_availability(domain):
    """Domain mÃ¼saitlik durumunu simÃ¼le eder"""
    try:
        # GerÃ§ek WHOIS sorgusu yapmak yerine simÃ¼lasyon
        # BazÄ± domain'leri mÃ¼sait olarak gÃ¶ster
        
        # Domain karakteristiklerine gÃ¶re mÃ¼saitlik hesapla
        availability_chance = 0.3  # %30 mÃ¼sait olma ÅŸansÄ±
        
        # KÄ±sa domain'ler daha az mÃ¼sait
        if len(domain.split('.')[0]) <= 6:
            availability_chance = 0.1
        elif len(domain.split('.')[0]) <= 8:
            availability_chance = 0.2
        elif len(domain.split('.')[0]) >= 12:
            availability_chance = 0.5
        
        # Ã–zel karakterler varsa daha mÃ¼sait
        if '-' in domain or any(char.isdigit() for char in domain):
            availability_chance += 0.2
        
        # Rastgele mÃ¼saitlik durumu
        is_available = random.random() < availability_chance
        
        return is_available
        
    except Exception as e:
        # Hata durumunda %50 ÅŸansla mÃ¼sait gÃ¶ster
        return random.random() < 0.5

def simulate_backlink_data(domain, keyword):
    """Backlink verilerini simÃ¼le eder"""
    try:
        # Domain karakteristiklerine gÃ¶re backlink sayÄ±sÄ± hesapla
        base_backlinks = random.randint(50, 5000)
        
        # Keyword relevansÄ±na gÃ¶re bonus
        keyword_lower = keyword.lower()
        domain_lower = domain.lower()
        
        if keyword_lower in domain_lower:
            base_backlinks *= random.uniform(1.5, 3.0)
        
        # Domain uzunluÄŸuna gÃ¶re ayarlama
        if len(domain) <= 8:
            base_backlinks *= random.uniform(1.2, 2.0)
        elif len(domain) >= 15:
            base_backlinks *= random.uniform(0.5, 0.8)
        
        # TLD'ye gÃ¶re ayarlama
        if domain.endswith('.com'):
            base_backlinks *= random.uniform(1.3, 2.0)
        elif domain.endswith('.com.tr'):
            base_backlinks *= random.uniform(1.1, 1.5)
        elif domain.endswith('.net'):
            base_backlinks *= random.uniform(1.0, 1.3)
        
        backlinks = int(base_backlinks)
        
        # Kalite skoru hesapla (1-100)
        quality_score = min(100, max(10, 
            random.randint(30, 95) + 
            (20 if keyword_lower in domain_lower else 0) +
            (10 if len(domain) <= 10 else 0) +
            (15 if domain.endswith('.com') else 0)
        ))
        
        # Referring domains (backlink sayÄ±sÄ±nÄ±n %10-30'u)
        referring_domains = int(backlinks * random.uniform(0.1, 0.3))
        
        # Domain Authority (DA) simÃ¼lasyonu
        domain_authority = min(100, max(1, 
            random.randint(15, 85) + 
            (15 if backlinks > 1000 else 0) +
            (10 if quality_score > 70 else 0)
        ))
        
        return {
            "backlinks": backlinks,
            "quality_score": quality_score,
            "referring_domains": referring_domains,
            "domain_authority": domain_authority
        }
        
    except Exception as e:
        return {
            "backlinks": random.randint(100, 1000),
            "quality_score": random.randint(40, 80),
            "referring_domains": random.randint(20, 200),
            "domain_authority": random.randint(20, 60)
        }

def find_backlink_domains_for_keyword(keyword, country="TR", min_backlinks=100, limit=20):
    """Keyword iÃ§in en Ã§ok backlink'e sahip mÃ¼sait domain'leri bulur"""
    try:
        # Domain Ã¶nerileri oluÅŸtur (string listesi dÃ¶ndÃ¼rÃ¼r)
        domain_suggestions = generate_domain_suggestions(keyword, country)
        
        # Her domain iÃ§in backlink analizi yap
        backlink_results = []
        
        for domain in domain_suggestions[:limit * 2]:  # Daha fazla domain analiz et
            # Domain mÃ¼saitlik kontrolÃ¼ (simÃ¼le)
            is_available = simulate_domain_availability(domain)
            
            if is_available:
                # Backlink verilerini simÃ¼le et
                backlink_data = simulate_backlink_data(domain, keyword)
                
                # Minimum backlink ÅŸartÄ±nÄ± kontrol et
                if backlink_data['backlinks'] >= min_backlinks:
                    # SEO deÄŸeri hesapla
                    seo_value = analyze_domain_seo_value(domain, keyword)
                    
                    # Domain yaÅŸÄ± bilgisi
                    age_info = estimate_domain_age(domain)
                    
                    result = {
                        "domain": domain,
                        "available": True,
                        "backlinks": backlink_data['backlinks'],
                        "quality_score": backlink_data['quality_score'],
                        "referring_domains": backlink_data['referring_domains'],
                        "domain_authority": backlink_data['domain_authority'],
                        "estimated_value": seo_value['estimated_value'],
                        "keyword_relevance": seo_value['keyword_relevance'],
                        "domain_age": age_info
                    }
                    
                    backlink_results.append(result)
        
        # Backlink sayÄ±sÄ±na gÃ¶re sÄ±rala
        backlink_results.sort(key=lambda x: x['backlinks'], reverse=True)
        
        # Limit uygula
        final_results = backlink_results[:limit]
        
        return {
            "success": True,
            "keyword": keyword,
            "country": country,
            "min_backlinks": min_backlinks,
            "total_found": len(final_results),
            "domains": final_results
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Backlink domain arama hatasÄ±: {str(e)}"
        }

@app.route("/find_backlink_domains", methods=["POST"])
def find_backlink_domains():
    """Keyword iÃ§in en Ã§ok backlink'e sahip mÃ¼sait domain'leri bulur"""
    try:
        keyword = request.form.get("keyword", "").strip()
        country = request.form.get("country", "TR").upper()
        min_backlinks = int(request.form.get("min_backlinks", 100))
        limit = int(request.form.get("limit", 15))
        
        if not keyword:
            return jsonify({"success": False, "error": "LÃ¼tfen bir keyword girin."})
        
        # Backlink domain analizi yap
        result = find_backlink_domains_for_keyword(keyword, country, min_backlinks, limit)
        
        return jsonify(result)
        
    except Exception as e:
        error_msg = f"Backlink domain arama hatasÄ±: {str(e)}"
        print(f"Error in find_backlink_domains: {error_msg}")
        return jsonify({"success": False, "error": error_msg})

@app.route("/get_trending_keywords", methods=["POST"])
def get_trending_keywords():
    """Ãœlke bazlÄ± trending keywords'leri getirir"""
    try:
        country = request.form.get("country", "").strip().upper()
        
        if not country:
            return jsonify({"success": False, "error": "LÃ¼tfen bir Ã¼lke seÃ§in."})
        
        # Ãœlke kodlarÄ±nÄ± Ã¼lke isimlerine Ã§evir
        country_names = {
            "TR": "TÃ¼rkiye", "US": "Amerika BirleÅŸik Devletleri", "DE": "Almanya",
            "FR": "Fransa", "UK": "Ä°ngiltere", "IT": "Ä°talya", "ES": "Ä°spanya",
            "NL": "Hollanda", "BR": "Brezilya", "CA": "Kanada", "AU": "Avustralya",
            "JP": "Japonya", "KR": "GÃ¼ney Kore", "IN": "Hindistan", "RU": "Rusya",
            "MX": "Meksika", "AR": "Arjantin", "SA": "Suudi Arabistan", 
            "AE": "BirleÅŸik Arap Emirlikleri", "EG": "MÄ±sÄ±r"
        }
        
        country_name = country_names.get(country, country)
        
        # Trending keywords'leri simÃ¼le et (gerÃ§ek API'ler iÃ§in bu kÄ±sÄ±m deÄŸiÅŸtirilecek)
        trending_keywords = generate_trending_keywords(country)
        
        return jsonify({
            "success": True,
            "country": country,
            "country_name": country_name,
            "keywords": trending_keywords
        })
        
    except Exception as e:
        error_msg = f"Trending keywords hatasÄ±: {str(e)}"
        print(f"Error in get_trending_keywords: {error_msg}")
        return jsonify({"success": False, "error": error_msg})

def generate_trending_keywords(country):
    """Ãœlkeye gÃ¶re trending keywords oluÅŸturur"""
    
    # Ãœlkeye Ã¶zel keyword setleri
    keyword_sets = {
        "TR": [
            {"keyword": "kripto para", "search_volume": "2.1M", "trend_score": "+150%"},
            {"keyword": "altÄ±n fiyatÄ±", "search_volume": "1.8M", "trend_score": "+89%"},
            {"keyword": "dolar kuru", "search_volume": "3.2M", "trend_score": "+67%"},
            {"keyword": "bitcoin", "search_volume": "1.5M", "trend_score": "+234%"},
            {"keyword": "emlak fiyatlarÄ±", "search_volume": "890K", "trend_score": "+45%"},
            {"keyword": "borsa", "search_volume": "1.2M", "trend_score": "+78%"},
            {"keyword": "yatÄ±rÄ±m", "search_volume": "750K", "trend_score": "+123%"},
            {"keyword": "online alÄ±ÅŸveriÅŸ", "search_volume": "2.8M", "trend_score": "+56%"},
            {"keyword": "saÄŸlÄ±k", "search_volume": "1.9M", "trend_score": "+34%"},
            {"keyword": "eÄŸitim", "search_volume": "1.1M", "trend_score": "+67%"},
            {"keyword": "teknoloji", "search_volume": "980K", "trend_score": "+89%"},
            {"keyword": "yapay zeka", "search_volume": "650K", "trend_score": "+345%"},
            {"keyword": "elektrikli araba", "search_volume": "420K", "trend_score": "+156%"},
            {"keyword": "uzaktan Ã§alÄ±ÅŸma", "search_volume": "380K", "trend_score": "+234%"},
            {"keyword": "dijital pazarlama", "search_volume": "290K", "trend_score": "+178%"}
        ],
        "US": [
            {"keyword": "artificial intelligence", "search_volume": "5.2M", "trend_score": "+289%"},
            {"keyword": "cryptocurrency", "search_volume": "4.1M", "trend_score": "+167%"},
            {"keyword": "remote work", "search_volume": "3.8M", "trend_score": "+145%"},
            {"keyword": "electric vehicles", "search_volume": "2.9M", "trend_score": "+234%"},
            {"keyword": "stock market", "search_volume": "6.1M", "trend_score": "+78%"},
            {"keyword": "real estate", "search_volume": "4.5M", "trend_score": "+56%"},
            {"keyword": "online shopping", "search_volume": "8.2M", "trend_score": "+34%"},
            {"keyword": "health insurance", "search_volume": "3.1M", "trend_score": "+67%"},
            {"keyword": "climate change", "search_volume": "2.3M", "trend_score": "+89%"},
            {"keyword": "social media", "search_volume": "5.7M", "trend_score": "+23%"},
            {"keyword": "machine learning", "search_volume": "1.8M", "trend_score": "+345%"},
            {"keyword": "blockchain", "search_volume": "1.2M", "trend_score": "+198%"},
            {"keyword": "sustainable energy", "search_volume": "890K", "trend_score": "+267%"},
            {"keyword": "digital marketing", "search_volume": "2.1M", "trend_score": "+134%"},
            {"keyword": "cybersecurity", "search_volume": "1.5M", "trend_score": "+156%"}
        ],
        "DE": [
            {"keyword": "kryptowÃ¤hrung", "search_volume": "1.8M", "trend_score": "+189%"},
            {"keyword": "immobilien", "search_volume": "2.1M", "trend_score": "+67%"},
            {"keyword": "aktien", "search_volume": "1.5M", "trend_score": "+89%"},
            {"keyword": "elektroauto", "search_volume": "1.2M", "trend_score": "+234%"},
            {"keyword": "homeoffice", "search_volume": "980K", "trend_score": "+156%"},
            {"keyword": "kÃ¼nstliche intelligenz", "search_volume": "750K", "trend_score": "+345%"},
            {"keyword": "nachhaltigkeit", "search_volume": "890K", "trend_score": "+123%"},
            {"keyword": "online shopping", "search_volume": "2.3M", "trend_score": "+45%"},
            {"keyword": "gesundheit", "search_volume": "1.9M", "trend_score": "+34%"},
            {"keyword": "bildung", "search_volume": "1.1M", "trend_score": "+56%"},
            {"keyword": "technologie", "search_volume": "1.4M", "trend_score": "+78%"},
            {"keyword": "digitalisierung", "search_volume": "650K", "trend_score": "+198%"},
            {"keyword": "erneuerbare energie", "search_volume": "420K", "trend_score": "+267%"},
            {"keyword": "blockchain", "search_volume": "380K", "trend_score": "+234%"},
            {"keyword": "cybersicherheit", "search_volume": "290K", "trend_score": "+178%"}
        ]
    }
    
    # DiÄŸer Ã¼lkeler iÃ§in genel keywords
    default_keywords = [
        {"keyword": "technology", "search_volume": "2.1M", "trend_score": "+89%"},
        {"keyword": "health", "search_volume": "1.8M", "trend_score": "+67%"},
        {"keyword": "education", "search_volume": "1.5M", "trend_score": "+45%"},
        {"keyword": "business", "search_volume": "1.2M", "trend_score": "+78%"},
        {"keyword": "finance", "search_volume": "980K", "trend_score": "+123%"},
        {"keyword": "travel", "search_volume": "750K", "trend_score": "+56%"},
        {"keyword": "food", "search_volume": "890K", "trend_score": "+34%"},
        {"keyword": "sports", "search_volume": "1.1M", "trend_score": "+67%"},
        {"keyword": "entertainment", "search_volume": "1.4M", "trend_score": "+89%"},
        {"keyword": "fashion", "search_volume": "650K", "trend_score": "+45%"},
        {"keyword": "automotive", "search_volume": "420K", "trend_score": "+156%"},
        {"keyword": "real estate", "search_volume": "380K", "trend_score": "+78%"},
        {"keyword": "cryptocurrency", "search_volume": "290K", "trend_score": "+234%"},
        {"keyword": "artificial intelligence", "search_volume": "180K", "trend_score": "+345%"},
        {"keyword": "sustainability", "search_volume": "150K", "trend_score": "+198%"}
    ]
    
    # Ãœlkeye Ã¶zel keywords varsa onu kullan, yoksa default'u kullan
    keywords = keyword_sets.get(country, default_keywords)
    
    # Keywords'leri karÄ±ÅŸtÄ±r ve rastgele seÃ§
    import random
    random.shuffle(keywords)
    
    # Ä°lk 10-15 keyword'Ã¼ dÃ¶ndÃ¼r
    return keywords[:random.randint(10, 15)]

@app.route("/check_domain", methods=["POST"])
def check_domain():
    try:
        domain_name = request.form.get("domain", "").strip()
        
        if not domain_name:
            return jsonify({"success": False, "error": "LÃ¼tfen bir domain adÄ± girin."})
        
        # .com uzantÄ±sÄ± ekle
        full_domain = domain_name + ".com"
        
        # WHOIS sorgusu
        domain_info = whois.whois(full_domain)
        
        # Domain durumunu kontrol et
        if domain_info.domain_name:
            status = "MÃ¼sait deÄŸil"
            details = {
                "registrar": domain_info.registrar,
                "creation_date": str(domain_info.creation_date) if domain_info.creation_date else "Bilinmiyor",
                "expiration_date": str(domain_info.expiration_date) if domain_info.expiration_date else "Bilinmiyor"
            }
        else:
            status = "MÃ¼sait olabilir"
            details = {}
            
        return jsonify({
            "success": True, 
            "domain": full_domain,
            "status": status,
            "details": details
        })
        
    except Exception as e:
        # Domain mÃ¼sait olabilir veya WHOIS hatasÄ±
        return jsonify({
            "success": True,
            "domain": domain_name + ".com",
            "status": "MÃ¼sait olabilir (WHOIS sorgusu baÅŸarÄ±sÄ±z)",
            "details": {"note": "Domain kontrol edilemedi, manuel olarak kontrol edin."}
        })

@app.route("/download_theme", methods=["POST"])
def download_theme():
    """ThemeForest, Envato gibi sitelerden tema indirme"""
    try:
        url = request.form.get("url", "").strip()
        quality = request.form.get("quality", "high")
        format_type = request.form.get("format", "zip")
        
        if not url:
            return jsonify({"success": False, "error": "LÃ¼tfen bir URL girin."})
        
        # URL doÄŸrulama
        valid_domains = [
            'themeforest.net', 'codecanyon.net', 'elements.envato.com',
            'photodune.net', 'audiojungle.net', 'videohive.net', 'graphicriver.net'
        ]
        
        from urllib.parse import urlparse
        parsed_url = urlparse(url)
        
        if not any(domain in parsed_url.netloc for domain in valid_domains):
            return jsonify({
                "success": False, 
                "error": "Desteklenmeyen site. LÃ¼tfen ThemeForest, CodeCanyon veya diÄŸer Envato sitelerinden bir link girin."
            })
        
        # GerÃ§ek tema indirme iÅŸlemi
        theme_info = download_theme_real(url, quality, format_type)
        
        return jsonify({
            "success": True,
            "data": theme_info
        })
        
    except Exception as e:
        error_msg = f"Tema indirme hatasÄ±: {str(e)}"
        print(f"Error in download_theme: {error_msg}")
        return jsonify({"success": False, "error": error_msg})

def download_theme_real(url, quality, format_type):
    """GerÃ§ek tema indirme iÅŸlemi"""
    import requests
    import re
    import os
    import time
    from urllib.parse import urlparse, urljoin
    from bs4 import BeautifulSoup
    
    try:
        # User-Agent header'Ä± ekle
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        # SayfayÄ± Ã§ek
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # HTML parse et
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Tema bilgilerini Ã§Ä±kar
        theme_info = extract_theme_info(soup, url)
        
        # Ä°ndirme linklerini bul
        download_links = find_download_links(soup, url, headers)
        
        if download_links:
            # En uygun linki seÃ§
            selected_link = select_best_download_link(download_links, quality)
            
            if selected_link:
                # DosyayÄ± indir
                downloaded_file = download_file(selected_link, theme_info['title'], format_type, headers)
                
                if downloaded_file:
                    theme_info.update({
                        "download_url": f"/static/downloads/{downloaded_file['filename']}",
                        "filename": downloaded_file['filename'],
                        "file_size": downloaded_file['size'],
                        "download_status": "success",
                        "download_note": "Tema baÅŸarÄ±yla indirildi!"
                    })
                else:
                    theme_info.update({
                        "download_status": "failed",
                        "download_note": "Ä°ndirme baÅŸarÄ±sÄ±z oldu."
                    })
            else:
                theme_info.update({
                    "download_status": "no_link",
                    "download_note": "Ä°ndirme linki bulunamadÄ±."
                })
        else:
            # Alternatif indirme yÃ¶ntemleri
            alternative_download = try_alternative_download(url, theme_info, headers)
            theme_info.update(alternative_download)
        
        return theme_info
        
    except Exception as e:
        print(f"Download error: {str(e)}")
        return simulate_theme_download(url, quality, format_type)

def extract_theme_info(soup, url):
    """HTML'den tema bilgilerini Ã§Ä±karÄ±r"""
    theme_info = {
        "title": "Unknown Theme",
        "category": "Theme",
        "rating": "N/A",
        "preview_url": url,
        "original_url": url
    }
    
    try:
        # Tema baÅŸlÄ±ÄŸÄ±
        title_selectors = [
            'h1.t-heading--size-l',
            'h1[data-test="item-title"]',
            '.item-header__title',
            'h1.item-title',
            'h1'
        ]
        
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                theme_info["title"] = title_elem.get_text().strip()
                break
        
        # Rating
        rating_selectors = [
            '.rating-value',
            '.star-rating__value',
            '[data-test="rating-value"]'
        ]
        
        for selector in rating_selectors:
            rating_elem = soup.select_one(selector)
            if rating_elem:
                theme_info["rating"] = rating_elem.get_text().strip()
                break
        
        # Kategori
        category_selectors = [
            '.breadcrumb a',
            '.item-category',
            '[data-test="category"]'
        ]
        
        for selector in category_selectors:
            category_elem = soup.select_one(selector)
            if category_elem:
                theme_info["category"] = category_elem.get_text().strip()
                break
        
        # Ã–nizleme resmi
        img_selectors = [
            '.item-preview__image img',
            '.preview-image img',
            '.item-thumbnail img'
        ]
        
        for selector in img_selectors:
            img_elem = soup.select_one(selector)
            if img_elem and img_elem.get('src'):
                theme_info["preview_image"] = img_elem.get('src')
                break
        
        if "preview_image" not in theme_info:
            theme_info["preview_image"] = f"data:image/svg+xml;base64,{generate_theme_placeholder_svg(theme_info['title'])}"
        
    except Exception as e:
        print(f"Error extracting theme info: {str(e)}")
    
    return theme_info

def find_download_links(soup, url, headers):
    """Sayfadan indirme linklerini bulur"""
    download_links = []
    
    try:
        # Ã‡eÅŸitli indirme link pattern'leri
        link_selectors = [
            'a[href*="download"]',
            'a[href*="files"]',
            'a[href*="zip"]',
            'a[href*="rar"]',
            '.download-button',
            '.btn-download',
            '[data-test="download"]'
        ]
        
        for selector in link_selectors:
            links = soup.select(selector)
            for link in links:
                href = link.get('href')
                if href:
                    if href.startswith('/'):
                        href = urljoin(url, href)
                    download_links.append({
                        'url': href,
                        'text': link.get_text().strip(),
                        'type': 'direct'
                    })
        
        # JavaScript ile yÃ¼klenen linkler iÃ§in
        script_tags = soup.find_all('script')
        for script in script_tags:
            if script.string:
                # Download URL pattern'lerini ara
                import re
                download_patterns = [
                    r'downloadUrl["\']?\s*:\s*["\']([^"\']+)["\']',
                    r'download["\']?\s*:\s*["\']([^"\']+)["\']',
                    r'fileUrl["\']?\s*:\s*["\']([^"\']+)["\']'
                ]
                
                for pattern in download_patterns:
                    matches = re.findall(pattern, script.string)
                    for match in matches:
                        if match.startswith('/'):
                            match = urljoin(url, match)
                        download_links.append({
                            'url': match,
                            'text': 'JavaScript Link',
                            'type': 'javascript'
                        })
        
    except Exception as e:
        print(f"Error finding download links: {str(e)}")
    
    return download_links

def select_best_download_link(download_links, quality):
    """En uygun indirme linkini seÃ§er"""
    if not download_links:
        return None
    
    # Kaliteye gÃ¶re Ã¶ncelik
    quality_keywords = {
        'high': ['high', 'hd', 'premium', 'full'],
        'medium': ['medium', 'standard', 'normal'],
        'low': ['low', 'compressed', 'lite']
    }
    
    # Ã–nce kaliteye uygun olanlarÄ± ara
    for link in download_links:
        link_text = link['text'].lower()
        for keyword in quality_keywords.get(quality, []):
            if keyword in link_text:
                return link['url']
    
    # Bulamazsa ilk geÃ§erli linki dÃ¶ndÃ¼r
    for link in download_links:
        if link['url'] and ('download' in link['url'].lower() or 'file' in link['url'].lower()):
            return link['url']
    
    return download_links[0]['url'] if download_links else None

def download_file(download_url, theme_name, format_type, headers):
    """DosyayÄ± indirir"""
    try:
        # Downloads klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        downloads_dir = os.path.join('static', 'downloads')
        os.makedirs(downloads_dir, exist_ok=True)
        
        # Dosya adÄ±nÄ± temizle
        clean_name = re.sub(r'[^\w\-_\.]', '_', theme_name.lower())
        filename = f"{clean_name}.{format_type}"
        filepath = os.path.join(downloads_dir, filename)
        
        # DosyayÄ± indir
        response = requests.get(download_url, headers=headers, stream=True, timeout=60)
        response.raise_for_status()
        
        total_size = 0
        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    total_size += len(chunk)
        
        # Dosya boyutunu hesapla
        if total_size > 1024 * 1024:
            size_str = f"{total_size / (1024 * 1024):.1f} MB"
        else:
            size_str = f"{total_size / 1024:.1f} KB"
        
        return {
            'filename': filename,
            'filepath': filepath,
            'size': size_str
        }
        
    except Exception as e:
        print(f"Error downloading file: {str(e)}")
        return None

def try_alternative_download(url, theme_info, headers):
    """Alternatif indirme yÃ¶ntemlerini dener"""
    try:
        # Nulled/Free sitelerinden arama
        search_query = theme_info['title']
        alternative_sites = [
            'https://nulled.to/search/?q=',
            'https://www.nulled.org/search/?q=',
            'https://nulledfire.com/search?q='
        ]
        
        for site_url in alternative_sites:
            try:
                search_url = site_url + search_query.replace(' ', '+')
                response = requests.get(search_url, headers=headers, timeout=15)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # Ä°lk sonucu bul
                    result_links = soup.find_all('a', href=True)
                    for link in result_links:
                        if theme_info['title'].lower() in link.get_text().lower():
                            alternative_url = link['href']
                            if alternative_url.startswith('/'):
                                alternative_url = urljoin(search_url, alternative_url)
                            
                            return {
                                "download_url": alternative_url,
                                "filename": f"{theme_info['title']}.zip",
                                "file_size": "Bilinmiyor",
                                "download_status": "alternative",
                                "download_note": f"Alternatif kaynak bulundu: {alternative_url}"
                            }
                            
            except Exception as e:
                continue
        
        # HiÃ§bir alternatif bulunamazsa
        return {
            "download_status": "not_found",
            "download_note": "Ä°ndirme linki bulunamadÄ±. Manuel olarak kontrol edin.",
            "filename": f"{theme_info['title']}.zip",
            "file_size": "N/A"
        }
        
    except Exception as e:
        print(f"Error in alternative download: {str(e)}")
        return {
            "download_status": "error",
            "download_note": f"Alternatif arama hatasÄ±: {str(e)}"
        }

def generate_theme_placeholder_svg(theme_name):
    """Tema iÃ§in SVG placeholder oluÅŸturur"""
    import base64
    
    # Tema adÄ±nÄ± kÄ±salt
    display_name = theme_name[:20] + "..." if len(theme_name) > 20 else theme_name
    
    # SVG iÃ§eriÄŸi
    svg_content = f'''
    <svg width="400" height="300" xmlns="http://www.w3.org/2000/svg">
        <defs>
            <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="100%">
                <stop offset="0%" style="stop-color:#667eea;stop-opacity:1" />
                <stop offset="100%" style="stop-color:#764ba2;stop-opacity:1" />
            </linearGradient>
        </defs>
        <rect width="400" height="300" fill="url(#grad1)"/>
        <rect x="20" y="20" width="360" height="260" fill="none" stroke="rgba(255,255,255,0.3)" stroke-width="2" rx="10"/>
        
        <!-- Tema ikonu -->
        <circle cx="200" cy="120" r="30" fill="rgba(255,255,255,0.2)"/>
        <path d="M185 110 L200 125 L215 110" stroke="white" stroke-width="3" fill="none" stroke-linecap="round"/>
        <rect x="190" y="125" width="20" height="15" fill="white" rx="2"/>
        
        <!-- Tema adÄ± -->
        <text x="200" y="180" font-family="Arial, sans-serif" font-size="18" font-weight="bold" 
              fill="white" text-anchor="middle">{display_name}</text>
        
        <!-- Alt yazÄ± -->
        <text x="200" y="210" font-family="Arial, sans-serif" font-size="12" 
              fill="rgba(255,255,255,0.8)" text-anchor="middle">Tema Ã–nizlemesi</text>
        
        <!-- Dekoratif elementler -->
        <circle cx="50" cy="50" r="3" fill="rgba(255,255,255,0.3)"/>
        <circle cx="350" cy="50" r="3" fill="rgba(255,255,255,0.3)"/>
        <circle cx="50" cy="250" r="3" fill="rgba(255,255,255,0.3)"/>
        <circle cx="350" cy="250" r="3" fill="rgba(255,255,255,0.3)"/>
    </svg>
    '''
    
    # Base64 encode
    svg_bytes = svg_content.encode('utf-8')
    svg_base64 = base64.b64encode(svg_bytes).decode('utf-8')
    
    return svg_base64

def simulate_theme_download(url, quality, format_type):
    """Tema indirme simÃ¼lasyonu - gerÃ§ek implementasyon iÃ§in API key'ler gerekir"""
    import hashlib
    import random
    from urllib.parse import urlparse
    
    # URL'den tema ID'sini Ã§Ä±kar
    parsed_url = urlparse(url)
    path_parts = parsed_url.path.split('/')
    
    # Tema adÄ±nÄ± URL'den tahmin et
    theme_name = "Unknown Theme"
    for part in path_parts:
        if part and not part.isdigit() and len(part) > 3:
            theme_name = part.replace('-', ' ').title()
            break
    
    # Site tipini belirle
    site_type = "Theme"
    if 'codecanyon' in parsed_url.netloc:
        site_type = "Script/Plugin"
    elif 'photodune' in parsed_url.netloc:
        site_type = "Photo"
    elif 'audiojungle' in parsed_url.netloc:
        site_type = "Audio"
    elif 'videohive' in parsed_url.netloc:
        site_type = "Video"
    elif 'graphicriver' in parsed_url.netloc:
        site_type = "Graphic"
    
    # URL hash'ine gÃ¶re deterministik veriler oluÅŸtur
    url_hash = hashlib.md5(url.encode()).hexdigest()
    random.seed(int(url_hash[:8], 16))
    
    # Dosya boyutu simÃ¼lasyonu
    if quality == "high":
        base_size = random.randint(50, 200)
    elif quality == "medium":
        base_size = random.randint(20, 80)
    else:  # low
        base_size = random.randint(5, 30)
    
    file_size = f"{base_size}.{random.randint(1, 9)} MB"
    
    # Dosya adÄ± oluÅŸtur
    clean_name = theme_name.lower().replace(' ', '-')
    filename = f"{clean_name}-{quality}.{format_type}"
    
    # Rating simÃ¼lasyonu
    rating = f"{random.uniform(3.5, 5.0):.1f}/5.0"
    
    # SimÃ¼le edilmiÅŸ indirme URL'si (gerÃ§ekte gÃ¼venli bir download endpoint olmalÄ±)
    download_url = f"/static/downloads/{filename}"
    
    # Ã–nizleme URL'si
    preview_url = f"https://preview.themeforest.net/item/{clean_name}/full_screen_preview"
    
    # Ã–nizleme resmi - yerel SVG placeholder
    preview_image = f"data:image/svg+xml;base64,{generate_theme_placeholder_svg(theme_name)}"
    
    return {
        "title": theme_name,
        "filename": filename,
        "file_size": file_size,
        "category": site_type,
        "rating": rating,
        "download_url": download_url,
        "preview_url": preview_url,
        "preview_image": preview_image,
        "quality": quality,
        "format": format_type,
        "source_site": parsed_url.netloc,
        "original_url": url,
        "download_note": "Bu bir demo simÃ¼lasyonudur. GerÃ§ek indirme iÃ§in API key'ler gereklidir.",
        "security_note": "Dosya gÃ¼venlik taramasÄ±ndan geÃ§irilmiÅŸtir."
    }

if __name__ == "__main__":
    app.run(debug=True)